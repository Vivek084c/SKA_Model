{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Iris dataset using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = torch.load(\"iris_subset_30_per_class.pt\")\n",
    "X = torch.stack([item[0] for item in iris])  # Shape: [1000, 1, 28, 28]\n",
    "y = torch.tensor([item[1] for item in iris])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform appropriate preprocessing (normalization, train/test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Xtrain))\n",
    "print(type(ytrain))\n",
    "print(type(Xtest))\n",
    "print(type(ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "30\n",
      "120\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(Xtrain))\n",
    "print(len(Xtest))\n",
    "print(len(ytrain))\n",
    "print(len(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000, 3.5000, 1.6000, 0.6000],\n",
       "        [5.1000, 3.5000, 1.4000, 0.2000],\n",
       "        [6.3000, 3.4000, 5.6000, 2.4000],\n",
       "        [6.4000, 2.8000, 5.6000, 2.2000],\n",
       "        [6.5000, 3.0000, 5.5000, 1.8000]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000, 3.0000, 1.6000, 0.2000],\n",
       "        [5.5000, 3.5000, 1.3000, 0.2000],\n",
       "        [5.6000, 2.5000, 3.9000, 1.1000],\n",
       "        [6.3000, 2.5000, 5.0000, 1.9000],\n",
       "        [5.2000, 3.4000, 1.4000, 0.2000]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest[0:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MinMaxScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = scaler.transform(Xtrain)\n",
    "Xtest = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1944444 , 0.62499998, 0.10169492, 0.20833334],\n",
       "       [0.22222215, 0.62499998, 0.06779661, 0.04166667],\n",
       "       [0.55555557, 0.58333335, 0.77966099, 0.95833337],\n",
       "       [0.58333332, 0.3333333 , 0.77966099, 0.87500002],\n",
       "       [0.61111107, 0.41666665, 0.76271185, 0.70833331]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1944444 , 0.41666665, 0.10169492, 0.04166667],\n",
       "       [0.33333329, 0.62499998, 0.05084745, 0.04166667],\n",
       "       [0.36111104, 0.20833333, 0.49152543, 0.41666668],\n",
       "       [0.55555557, 0.20833333, 0.67796609, 0.74999999],\n",
       "       [0.2499999 , 0.58333335, 0.06779661, 0.04166667]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest[0:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking the entire Xtrain for forward prop\n",
    "inputs = Xtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Adaptation (30%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the SKA model with 4 layers\n",
    "class SKAModel(nn.Module):\n",
    "    def __init__(self, input_size=4, layer_sizes=[8, 6, 3], K=50):\n",
    "        super(SKAModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.K = K  # Number of forward steps\n",
    "\n",
    "        # Initialize weights and biases as nn.ParameterList\n",
    "        self.weights = nn.ParameterList()\n",
    "        self.biases = nn.ParameterList()\n",
    "        prev_size = input_size\n",
    "        for size in layer_sizes:\n",
    "            self.weights.append(nn.Parameter(torch.randn(prev_size, size) * 0.01))\n",
    "            self.biases.append(nn.Parameter(torch.zeros(size)))\n",
    "            prev_size = size\n",
    "\n",
    "        # Tracking tensors for knowledge accumulation and entropy computation\n",
    "        self.Z = [None] * len(layer_sizes)  # Knowledge tensors per layer\n",
    "        self.D = [None] * len(layer_sizes)  # Decision probability tensors\n",
    "        self.D_prev = [None] * len(layer_sizes)  # Previous decisions for computing shifts\n",
    "        self.delta_D = [None] * len(layer_sizes)  # Decision shifts per step\n",
    "        self.entropy = [None] * len(layer_sizes)  # Layer-wise entropy storage\n",
    "\n",
    "        # Store entropy, cosine, and output distribution history for visualization\n",
    "        self.entropy_history = [[] for _ in range(len(layer_sizes))]\n",
    "        self.cosine_history = [[] for _ in range(len(layer_sizes))]\n",
    "        self.output_history = []  # New: Store mean output distribution (10 classes) per step\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Computes SKA forward pass, storing knowledge and decisions.\"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        #x = x.view(batch_size, -1)  # Flatten images --> dont need to perform this, we already have a 1d tensor\n",
    "\n",
    "        for l in range(len(self.layer_sizes)):\n",
    "            # Compute knowledge tensor Z = Wx + b\n",
    "            z = torch.mm(x, self.weights[l]) + self.biases[l]\n",
    "            # Apply sigmoid activation to get decision probabilities\n",
    "            d = torch.sigmoid(z)\n",
    "            # Store values for entropy computation\n",
    "            self.Z[l] = z\n",
    "            self.D[l] = d\n",
    "            x = d  # Output becomes input for the next layer\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def calculate_entropy(self):\n",
    "        \"\"\"Computes entropy reduction and cos(theta) per layer.\"\"\"\n",
    "        total_entropy = 0\n",
    "        for l in range(len(self.layer_sizes)):\n",
    "            if self.Z[l] is not None and self.D_prev[l] is not None and self.D[l] is not None:\n",
    "                # Compute decision shifts\n",
    "                self.delta_D[l] = self.D[l] - self.D_prev[l]\n",
    "                # Entropy reduction using SKA formula\n",
    "                dot_product = torch.sum(self.Z[l] * self.delta_D[l])\n",
    "                layer_entropy = -1 / np.log(2) * dot_product\n",
    "                self.entropy[l] = layer_entropy.item()\n",
    "                self.entropy_history[l].append(layer_entropy.item())\n",
    "\n",
    "                # Compute cos(theta) for alignment\n",
    "                z_norm = torch.norm(self.Z[l])\n",
    "                delta_d_norm = torch.norm(self.delta_D[l])\n",
    "                if z_norm > 0 and delta_d_norm > 0:\n",
    "                    cos_theta = dot_product / (z_norm * delta_d_norm)\n",
    "                    self.cosine_history[l].append(cos_theta.item())\n",
    "                else:\n",
    "                    self.cosine_history[l].append(0.0)  # Default if norms are zero\n",
    "\n",
    "                total_entropy += layer_entropy\n",
    "        return total_entropy\n",
    "    \n",
    "\n",
    "    def ska_update(self, inputs, learning_rate=0.01):\n",
    "        \"\"\"Updates weights using entropy-based learning without backpropagation.\"\"\"\n",
    "        for l in range(len(self.layer_sizes)):\n",
    "            if self.delta_D[l] is not None:\n",
    "                # Previous layer's output\n",
    "                prev_output = inputs.view(inputs.shape[0], -1) if l == 0 else self.D_prev[l-1]\n",
    "                # Compute sigmoid derivative: D * (1 - D)\n",
    "                d_prime = self.D[l] * (1 - self.D[l])\n",
    "                # Compute entropy gradient\n",
    "                gradient = -1 / np.log(2) * (self.Z[l] * d_prime + self.delta_D[l])\n",
    "                # Compute weight updates via outer product\n",
    "                dW = torch.matmul(prev_output.t(), gradient) / prev_output.shape[0]\n",
    "                # Update weights and biases\n",
    "                self.weights[l] = self.weights[l] - learning_rate * dW\n",
    "                self.biases[l] = self.biases[l] - learning_rate * gradient.mean(dim=0)\n",
    "\n",
    "    def initialize_tensors(self, batch_size):\n",
    "        \"\"\"Resets decision tensors at the start of each training iteration.\"\"\"\n",
    "        for l in range(len(self.layer_sizes)):\n",
    "            self.Z[l] = None         # Reset knowledge tensors\n",
    "            self.D[l] = None         # Reset current decision probabilities\n",
    "            self.D_prev[l] = None    # Reset previous decision probabilities\n",
    "            self.delta_D[l] = None   # Reset decision shifts\n",
    "            self.entropy[l] = None   # Reset entropy storage\n",
    "            self.entropy_history[l] = []  # Reset entropy history\n",
    "            self.cosine_history[l] = []   # Reset cosine history\n",
    "        self.output_history = []  # Reset output history\n",
    "        \n",
    "\n",
    "    def visualize_entropy_heatmap(self, step):\n",
    "        \"\"\"Dynamically scales the heatmap range and visualizes entropy reduction.\"\"\"\n",
    "        entropy_data = np.array(self.entropy_history)\n",
    "        vmin = np.min(entropy_data)  # Dynamically set minimum entropy value\n",
    "        vmax = 0.0  # Keep 0 as the upper limit for standardization\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(entropy_data, cmap=\"Blues_r\", vmin=vmin, vmax=vmax,  \n",
    "                    xticklabels=range(1, entropy_data.shape[1] + 1),\n",
    "                    yticklabels=[f\"Layer {i+1}\" for i in range(len(self.layer_sizes))])\n",
    "        plt.title(f\"Layer-wise Entropy Heatmap (Step {step})\")\n",
    "        plt.xlabel(\"Step Index K\")\n",
    "        plt.ylabel(\"Network Layers\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"output/entropy_heatmap_step_{step}.png\")\n",
    "        plt.show(block=False)  # Non-blocking\n",
    "        plt.pause(2)  # Wait for 2 seconds\n",
    "        plt.close()  # Close automatically\n",
    "\n",
    "    def visualize_cosine_heatmap(self, step):\n",
    "        \"\"\"Visualizes cos(theta) alignment heatmap with a diverging scale.\"\"\"\n",
    "        cosine_data = np.array(self.cosine_history)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(cosine_data, cmap=\"coolwarm_r\", vmin=-1.0, vmax=1.0,  \n",
    "                    xticklabels=range(1, cosine_data.shape[1] + 1),\n",
    "                    yticklabels=[f\"Layer {i+1}\" for i in range(len(self.layer_sizes))])\n",
    "        plt.title(f\"Layer-wise Cos(\\u03B8) Alignment Heatmap (Step {step})\")\n",
    "        plt.xlabel(\"Step Index K\")\n",
    "        plt.ylabel(\"Network Layers\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"output/cosine_heatmap_step_{step}.png\")\n",
    "        plt.show(block=False)  # Non-blocking\n",
    "        plt.pause(2)  # Wait for 2 seconds\n",
    "        plt.close()  # Close automatically\n",
    "\n",
    "    def visualize_output_distribution(self):\n",
    "        \"\"\"Plots the evolution of the 10-class output distribution over K steps.\"\"\"\n",
    "        output_data = np.array(self.output_history)  # Shape: [K, 10]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(output_data)  # Plot each class as a line\n",
    "        plt.title('Output Decision Probability Evolution Across Steps (Single Pass)')\n",
    "        plt.xlabel('Step Index K')\n",
    "        plt.ylabel('Mean Sigmoid Output')\n",
    "        plt.legend([f\"Class {i}\" for i in range(10)], loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"output/output_distribution_single_pass.png\")\n",
    "        plt.show(block=False)  # Non-blocking\n",
    "        plt.pause(2)  # Wait for 2 seconds\n",
    "        plt.close()  # Close automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the SKA model with 4 layers\n",
    "class SKAModel_iris(nn.Module):\n",
    "    def __init__(self, input_size=4, layer_sizes=[8, 6, 3], K=50):\n",
    "        super(SKAModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.K = K  # Number of forward steps\n",
    "\n",
    "        # Initialize weights and biases as nn.ParameterList\n",
    "        self.weights = nn.ParameterList()\n",
    "        self.biases = nn.ParameterList()\n",
    "        prev_size = input_size\n",
    "        for size in layer_sizes:\n",
    "            self.weights.append(nn.Parameter(torch.randn(prev_size, size) * 0.01))\n",
    "            self.biases.append(nn.Parameter(torch.zeros(size)))\n",
    "            prev_size = size\n",
    "\n",
    "        # Tracking tensors for knowledge accumulation and entropy computation\n",
    "        self.Z = [None] * len(layer_sizes)  # Knowledge tensors per layer\n",
    "        self.D = [None] * len(layer_sizes)  # Decision probability tensors\n",
    "        self.D_prev = [None] * len(layer_sizes)  # Previous decisions for computing shifts\n",
    "        self.delta_D = [None] * len(layer_sizes)  # Decision shifts per step\n",
    "        self.entropy = [None] * len(layer_sizes)  # Layer-wise entropy storage\n",
    "\n",
    "        # Store entropy, cosine, and output distribution history for visualization\n",
    "        self.entropy_history = [[] for _ in range(len(layer_sizes))]\n",
    "        self.cosine_history = [[] for _ in range(len(layer_sizes))]\n",
    "        self.output_history = []  # New: Store mean output distribution (10 classes) per step\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Computes SKA forward pass, storing knowledge and decisions.\"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        #x = x.view(batch_size, -1)  # Flatten images --> dont need to perform this, we already have a 1d tensor\n",
    "\n",
    "        for l in range(len(self.layer_sizes)):\n",
    "            # Compute knowledge tensor Z = Wx + b\n",
    "            z = torch.mm(x, self.weights[l]) + self.biases[l]\n",
    "            # Apply sigmoid activation to get decision probabilities\n",
    "            d = torch.sigmoid(z)\n",
    "            # Store values for entropy computation\n",
    "            self.Z[l] = z\n",
    "            self.D[l] = d\n",
    "            x = d  # Output becomes input for the next layer\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def calculate_entropy(self):\n",
    "        \"\"\"Computes entropy reduction and cos(theta) per layer.\"\"\"\n",
    "        total_entropy = 0\n",
    "        for l in range(len(self.layer_sizes)):\n",
    "            if self.Z[l] is not None and self.D_prev[l] is not None and self.D[l] is not None:\n",
    "                # Compute decision shifts\n",
    "                self.delta_D[l] = self.D[l] - self.D_prev[l]\n",
    "                # Entropy reduction using SKA formula\n",
    "                dot_product = torch.sum(self.Z[l] * self.delta_D[l])\n",
    "                layer_entropy = -1 / np.log(2) * dot_product\n",
    "                self.entropy[l] = layer_entropy.item()\n",
    "                self.entropy_history[l].append(layer_entropy.item())\n",
    "\n",
    "                # Compute cos(theta) for alignment\n",
    "                z_norm = torch.norm(self.Z[l])\n",
    "                delta_d_norm = torch.norm(self.delta_D[l])\n",
    "                if z_norm > 0 and delta_d_norm > 0:\n",
    "                    cos_theta = dot_product / (z_norm * delta_d_norm)\n",
    "                    self.cosine_history[l].append(cos_theta.item())\n",
    "                else:\n",
    "                    self.cosine_history[l].append(0.0)  # Default if norms are zero\n",
    "\n",
    "                total_entropy += layer_entropy\n",
    "        return total_entropy\n",
    "    \n",
    "\n",
    "    def ska_update(self, inputs, learning_rate=0.01):\n",
    "        \"\"\"Updates weights using entropy-based learning without backpropagation.\"\"\"\n",
    "        for l in range(len(self.layer_sizes)):\n",
    "            if self.delta_D[l] is not None:\n",
    "                # Previous layer's output\n",
    "                prev_output = inputs.view(inputs.shape[0], -1) if l == 0 else self.D_prev[l-1]\n",
    "                # Compute sigmoid derivative: D * (1 - D)\n",
    "                d_prime = self.D[l] * (1 - self.D[l])\n",
    "                # Compute entropy gradient\n",
    "                gradient = -1 / np.log(2) * (self.Z[l] * d_prime + self.delta_D[l])\n",
    "                # Compute weight updates via outer product\n",
    "                dW = torch.matmul(prev_output.t(), gradient) / prev_output.shape[0]\n",
    "                # Update weights and biases\n",
    "                self.weights[l] = self.weights[l] - learning_rate * dW\n",
    "                self.biases[l] = self.biases[l] - learning_rate * gradient.mean(dim=0)\n",
    "\n",
    "    def initialize_tensors(self, batch_size):\n",
    "        \"\"\"Resets decision tensors at the start of each training iteration.\"\"\"\n",
    "        for l in range(len(self.layer_sizes)):\n",
    "            self.Z[l] = None         # Reset knowledge tensors\n",
    "            self.D[l] = None         # Reset current decision probabilities\n",
    "            self.D_prev[l] = None    # Reset previous decision probabilities\n",
    "            self.delta_D[l] = None   # Reset decision shifts\n",
    "            self.entropy[l] = None   # Reset entropy storage\n",
    "            self.entropy_history[l] = []  # Reset entropy history\n",
    "            self.cosine_history[l] = []   # Reset cosine history\n",
    "        self.output_history = []  # Reset output history\n",
    "        \n",
    "\n",
    "    def visualize_entropy_heatmap(self, step):\n",
    "        \"\"\"Dynamically scales the heatmap range and visualizes entropy reduction.\"\"\"\n",
    "        entropy_data = np.array(self.entropy_history)\n",
    "        vmin = np.min(entropy_data)  # Dynamically set minimum entropy value\n",
    "        vmax = 0.0  # Keep 0 as the upper limit for standardization\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(entropy_data, cmap=\"Blues_r\", vmin=vmin, vmax=vmax,  \n",
    "                    xticklabels=range(1, entropy_data.shape[1] + 1),\n",
    "                    yticklabels=[f\"Layer {i+1}\" for i in range(len(self.layer_sizes))])\n",
    "        plt.title(f\"Layer-wise Entropy Heatmap (Step {step})\")\n",
    "        plt.xlabel(\"Step Index K\")\n",
    "        plt.ylabel(\"Network Layers\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"output/entropy_heatmap_step_{step}.png\")\n",
    "        plt.show(block=False)  # Non-blocking\n",
    "        plt.pause(2)  # Wait for 2 seconds\n",
    "        plt.close()  # Close automatically\n",
    "\n",
    "    def visualize_cosine_heatmap(self, step):\n",
    "        \"\"\"Visualizes cos(theta) alignment heatmap with a diverging scale.\"\"\"\n",
    "        cosine_data = np.array(self.cosine_history)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(cosine_data, cmap=\"coolwarm_r\", vmin=-1.0, vmax=1.0,  \n",
    "                    xticklabels=range(1, cosine_data.shape[1] + 1),\n",
    "                    yticklabels=[f\"Layer {i+1}\" for i in range(len(self.layer_sizes))])\n",
    "        plt.title(f\"Layer-wise Cos(\\u03B8) Alignment Heatmap (Step {step})\")\n",
    "        plt.xlabel(\"Step Index K\")\n",
    "        plt.ylabel(\"Network Layers\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"output/cosine_heatmap_step_{step}.png\")\n",
    "        plt.show(block=False)  # Non-blocking\n",
    "        plt.pause(2)  # Wait for 2 seconds\n",
    "        plt.close()  # Close automatically\n",
    "\n",
    "    def visualize_output_distribution(self):\n",
    "        \"\"\"Plots the evolution of the 10-class output distribution over K steps.\"\"\"\n",
    "        output_data = np.array(self.output_history)  # Shape: [K, 10]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(output_data)  # Plot each class as a line\n",
    "        plt.title('Output Decision Probability Evolution Across Steps (Single Pass)')\n",
    "        plt.xlabel('Step Index K')\n",
    "        plt.ylabel('Mean Sigmoid Output')\n",
    "        plt.legend([f\"Class {i}\" for i in range(10)], loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"output/output_distribution_single_pass.png\")\n",
    "        plt.show(block=False)  # Non-blocking\n",
    "        plt.pause(2)  # Wait for 2 seconds\n",
    "        plt.close()  # Close automatically\n",
    "\n",
    "\n",
    "    def evaluate(self, X, y_true):\n",
    "        \"\"\"Evaluate model using accuracy and confusion matrix.\"\"\"\n",
    "        outputs = self.forward(X).detach().cpu().numpy()\n",
    "        y_pred = np.argmax(outputs, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_knowledge_magnitude(self):\n",
    "        \"\"\"Visualizes the L2 norm of knowledge tensors over training steps.\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for l in range(len(self.layer_sizes)):\n",
    "            magnitudes = [torch.norm(z).item() for z in self.Z if z is not None]\n",
    "            plt.plot(magnitudes, label=f\"Layer {l + 1}\")\n",
    "        plt.title(\"Knowledge Tensor Magnitude Over Training\")\n",
    "        plt.xlabel(\"Training Steps\")\n",
    "        plt.ylabel(\"L2 Norm\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_weight_changes(self):\n",
    "        \"\"\"Plots the average weight changes over training steps.\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for l in range(len(self.layer_sizes)):\n",
    "            weight_norms = [torch.norm(w).item() for w in self.weights]\n",
    "            plt.plot(weight_norms, label=f\"Layer {l + 1}\")\n",
    "        plt.title(\"Weight Changes During Training\")\n",
    "        plt.xlabel(\"Training Steps\")\n",
    "        plt.ylabel(\"Weight Norm\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_decision_evolution(self):\n",
    "        \"\"\"Visualizes decision probability evolution across steps.\"\"\"\n",
    "        output_data = np.array(self.output_history)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(output_data)\n",
    "        plt.title(\"Decision Probability Evolution\")\n",
    "        plt.xlabel(\"Step Index K\")\n",
    "        plt.ylabel(\"Mean Sigmoid Output\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Model Tranining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the adapted SKA model on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameter\n",
    "\n",
    "model = SKAModel_iris()\n",
    "learning_rate = 0.01\n",
    "\n",
    "# SKA training over multiple forward steps\n",
    "total_entropy = 0\n",
    "step_count = 0\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilising the tensor for first step\n",
    "model.initialize_tensors(inputs.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1944444 , 0.62499998, 0.10169492, 0.20833334],\n",
       "       [0.22222215, 0.62499998, 0.06779661, 0.04166667],\n",
       "       [0.55555557, 0.58333335, 0.77966099, 0.95833337],\n",
       "       [0.58333332, 0.3333333 , 0.77966099, 0.87500002],\n",
       "       [0.61111107, 0.41666665, 0.76271185, 0.70833331],\n",
       "       [0.08333326, 0.6666666 , 0.        , 0.04166667],\n",
       "       [0.08333326, 0.45833328, 0.08474576, 0.04166667],\n",
       "       [0.38888879, 1.        , 0.08474576, 0.125     ],\n",
       "       [1.        , 0.74999995, 0.91525424, 0.79166667],\n",
       "       [0.66666658, 0.20833333, 0.81355934, 0.70833331],\n",
       "       [0.66666658, 0.45833328, 0.77966099, 0.95833337],\n",
       "       [0.69444446, 0.5       , 0.83050848, 0.91666665],\n",
       "       [0.33333329, 0.1666667 , 0.47457626, 0.41666668],\n",
       "       [0.22222215, 0.74999995, 0.15254237, 0.125     ],\n",
       "       [0.58333332, 0.3333333 , 0.77966099, 0.83333329],\n",
       "       [0.11111101, 0.5       , 0.05084745, 0.04166667],\n",
       "       [0.72222221, 0.45833328, 0.74576272, 0.83333329],\n",
       "       [0.47222218, 0.08333335, 0.50847457, 0.375     ],\n",
       "       [0.30555554, 0.58333335, 0.11864407, 0.04166667],\n",
       "       [0.08333326, 0.58333335, 0.06779661, 0.08333334],\n",
       "       [0.02777775, 0.5       , 0.05084745, 0.04166667],\n",
       "       [0.30555554, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.30555554, 0.58333335, 0.08474576, 0.125     ],\n",
       "       [0.55555557, 0.54166663, 0.6271186 , 0.62500001],\n",
       "       [0.16666664, 0.6666666 , 0.06779661, 0.        ],\n",
       "       [0.58333332, 0.37500002, 0.55932206, 0.49999998],\n",
       "       [0.1944444 , 0.58333335, 0.10169492, 0.125     ],\n",
       "       [0.38888879, 0.74999995, 0.11864407, 0.08333334],\n",
       "       [0.33333329, 0.20833333, 0.50847457, 0.49999998],\n",
       "       [0.22222215, 0.20833333, 0.33898305, 0.41666668],\n",
       "       [0.16666664, 0.1666667 , 0.38983049, 0.375     ],\n",
       "       [0.69444446, 0.41666665, 0.76271185, 0.83333329],\n",
       "       [0.33333329, 0.12499998, 0.50847457, 0.49999998],\n",
       "       [0.47222218, 0.58333335, 0.59322033, 0.62500001],\n",
       "       [0.1944444 , 0.12499998, 0.38983049, 0.375     ],\n",
       "       [0.13888889, 0.58333335, 0.10169492, 0.04166667],\n",
       "       [0.38888879, 0.37500002, 0.54237284, 0.49999998],\n",
       "       [0.2499999 , 0.62499998, 0.08474576, 0.04166667],\n",
       "       [0.41666668, 0.29166667, 0.69491523, 0.74999999],\n",
       "       [0.13888889, 0.58333335, 0.15254237, 0.04166667],\n",
       "       [0.80555547, 0.41666665, 0.81355934, 0.62500001],\n",
       "       [0.66666658, 0.41666665, 0.71186436, 0.91666665],\n",
       "       [0.61111107, 0.41666665, 0.81355934, 0.87500002],\n",
       "       [0.        , 0.41666665, 0.01694916, 0.        ],\n",
       "       [0.22222215, 0.70833333, 0.08474576, 0.125     ],\n",
       "       [0.44444443, 0.5       , 0.64406782, 0.70833331],\n",
       "       [0.22222215, 0.54166663, 0.11864407, 0.16666667],\n",
       "       [0.36111104, 0.37500002, 0.44067794, 0.49999998],\n",
       "       [0.77777772, 0.41666665, 0.83050848, 0.83333329],\n",
       "       [0.41666668, 0.24999995, 0.50847457, 0.45833335],\n",
       "       [0.66666658, 0.45833328, 0.57627119, 0.54166666],\n",
       "       [0.72222221, 0.5       , 0.79661012, 0.91666665],\n",
       "       [0.94444436, 0.3333333 , 0.96610165, 0.79166667],\n",
       "       [0.36111104, 0.29166667, 0.54237284, 0.49999998],\n",
       "       [0.1944444 , 0.54166663, 0.06779661, 0.04166667],\n",
       "       [0.61111107, 0.3333333 , 0.61016947, 0.58333333],\n",
       "       [0.55555557, 0.12499998, 0.57627119, 0.49999998],\n",
       "       [0.16666664, 0.20833333, 0.59322033, 0.66666669],\n",
       "       [0.08333326, 0.5       , 0.06779661, 0.04166667],\n",
       "       [0.22222215, 0.58333335, 0.08474576, 0.04166667],\n",
       "       [0.74999997, 0.5       , 0.6271186 , 0.54166666],\n",
       "       [0.38888879, 0.3333333 , 0.5254237 , 0.49999998],\n",
       "       [0.33333329, 0.24999995, 0.57627119, 0.45833335],\n",
       "       [0.1944444 , 0.6666666 , 0.06779661, 0.04166667],\n",
       "       [0.55555557, 0.20833333, 0.66101695, 0.58333333],\n",
       "       [0.36111104, 0.3333333 , 0.66101695, 0.79166667],\n",
       "       [0.94444436, 0.41666665, 0.86440675, 0.91666665],\n",
       "       [0.86111111, 0.3333333 , 0.86440675, 0.74999999],\n",
       "       [0.13888889, 0.41666665, 0.06779661, 0.        ],\n",
       "       [0.58333332, 0.29166667, 0.72881358, 0.74999999],\n",
       "       [0.1944444 , 0.58333335, 0.08474576, 0.04166667],\n",
       "       [0.30555554, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.22222215, 0.74999995, 0.08474576, 0.08333334],\n",
       "       [0.13888889, 0.41666665, 0.06779661, 0.08333334],\n",
       "       [0.13888889, 0.45833328, 0.10169492, 0.04166667],\n",
       "       [0.41666668, 0.8333333 , 0.03389831, 0.04166667],\n",
       "       [0.49999993, 0.41666665, 0.61016947, 0.54166666],\n",
       "       [0.69444446, 0.3333333 , 0.64406782, 0.54166666],\n",
       "       [0.55555557, 0.37500002, 0.77966099, 0.70833331],\n",
       "       [0.83333336, 0.37500002, 0.8983051 , 0.70833331],\n",
       "       [0.63888883, 0.41666665, 0.57627119, 0.54166666],\n",
       "       [0.36111104, 0.41666665, 0.59322033, 0.58333333],\n",
       "       [0.47222218, 0.29166667, 0.69491523, 0.62500001],\n",
       "       [0.16666664, 0.45833328, 0.08474576, 0.04166667],\n",
       "       [0.55555557, 0.54166663, 0.84745761, 1.        ],\n",
       "       [0.94444436, 0.74999995, 0.96610165, 0.87500002],\n",
       "       [0.30555554, 0.79166667, 0.05084745, 0.125     ],\n",
       "       [0.52777769, 0.3333333 , 0.64406782, 0.70833331],\n",
       "       [0.47222218, 0.37500002, 0.59322033, 0.58333333],\n",
       "       [0.1944444 , 0.5       , 0.03389831, 0.04166667],\n",
       "       [0.61111107, 0.5       , 0.69491523, 0.79166667],\n",
       "       [0.94444436, 0.24999995, 1.        , 0.91666665],\n",
       "       [0.41666668, 0.29166667, 0.69491523, 0.74999999],\n",
       "       [0.80555547, 0.6666666 , 0.86440675, 1.        ],\n",
       "       [0.52777769, 0.58333335, 0.74576272, 0.91666665],\n",
       "       [0.41666668, 0.3333333 , 0.69491523, 0.95833337],\n",
       "       [0.55555557, 0.29166667, 0.66101695, 0.70833331],\n",
       "       [0.30555554, 0.41666665, 0.59322033, 0.58333333],\n",
       "       [0.44444443, 0.41666665, 0.69491523, 0.70833331],\n",
       "       [0.66666658, 0.45833328, 0.6271186 , 0.58333333],\n",
       "       [0.66666658, 0.41666665, 0.67796609, 0.66666669],\n",
       "       [0.49999993, 0.3333333 , 0.6271186 , 0.45833335],\n",
       "       [0.52777769, 0.37500002, 0.55932206, 0.49999998],\n",
       "       [0.38888879, 0.3333333 , 0.59322033, 0.49999998],\n",
       "       [0.61111107, 0.41666665, 0.71186436, 0.79166667],\n",
       "       [0.2499999 , 0.29166667, 0.49152543, 0.54166666],\n",
       "       [0.63888883, 0.37500002, 0.61016947, 0.49999998],\n",
       "       [0.02777775, 0.41666665, 0.05084745, 0.04166667],\n",
       "       [0.44444443, 0.41666665, 0.54237284, 0.58333333],\n",
       "       [0.38888879, 0.20833333, 0.67796609, 0.79166667],\n",
       "       [0.66666658, 0.54166663, 0.79661012, 1.        ],\n",
       "       [0.58333332, 0.5       , 0.59322033, 0.58333333],\n",
       "       [0.72222221, 0.45833328, 0.66101695, 0.58333333],\n",
       "       [0.1944444 , 0.        , 0.42372881, 0.375     ],\n",
       "       [0.16666664, 0.41666665, 0.06779661, 0.04166667],\n",
       "       [0.1944444 , 0.62499998, 0.05084745, 0.08333334],\n",
       "       [0.47222218, 0.08333335, 0.67796609, 0.58333333],\n",
       "       [0.02777775, 0.37500002, 0.06779661, 0.04166667],\n",
       "       [0.16666664, 0.45833328, 0.08474576, 0.        ],\n",
       "       [0.66666658, 0.54166663, 0.79661012, 0.83333329]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.expand_dims(inputs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(inputs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Process K forward steps (without backpropagation)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(model\u001b[38;5;241m.\u001b[39mK):\n\u001b[0;32m----> 3\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Store mean output distribution for the final layer\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39moutput_history\u001b[38;5;241m.\u001b[39mappend(outputs\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# [10] vector\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[42], line 38\u001b[0m, in \u001b[0;36mSKAModel_iris.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#x = x.view(batch_size, -1)  # Flatten images --> dont need to perform this, we already have a 1d tensor\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_sizes)):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Compute knowledge tensor Z = Wx + b\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases[l]\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Apply sigmoid activation to get decision probabilities\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(z)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: self must be a matrix"
     ]
    }
   ],
   "source": [
    "# Process K forward steps (without backpropagation)\n",
    "for k in range(model.K):\n",
    "    outputs = model.forward(inputs)\n",
    "    # Store mean output distribution for the final layer\n",
    "    model.output_history.append(outputs.mean(dim=0).detach().cpu().numpy())  # [10] vector\n",
    "    if k > 0:  # Compute entropy after first step\n",
    "        batch_entropy = model.calculate_entropy()\n",
    "        model.ska_update(inputs, learning_rate)\n",
    "        total_entropy += batch_entropy\n",
    "        step_count += 1\n",
    "        print(f'Step: {k}, Total Steps: {step_count}, Entropy: {batch_entropy:.4f}')\n",
    "        model.visualize_entropy_heatmap(step_count)\n",
    "        model.visualize_cosine_heatmap(step_count)  # Add cosine heatmap\n",
    "    # Update previous decision tensors\n",
    "    model.D_prev = [d.clone().detach() if d is not None else None for d in model.D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Analysis and Comparison (20%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementing traditional model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Load and preprocess the Iris dataset\n",
    "# iris = load_iris()\n",
    "# X, y = iris.data, iris.target\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(Xtrain, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(ytrain, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(Xtest, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(ytest, dtype=torch.long)\n",
    "\n",
    "# Define a traditional feedforward neural network\n",
    "class TraditionalNN(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_sizes=[16, 8, 6], output_size=3):\n",
    "        super(TraditionalNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_size = input_size\n",
    "        for size in hidden_sizes:\n",
    "            self.layers.append(nn.Linear(prev_size, size))\n",
    "            prev_size = size\n",
    "        self.output_layer = nn.Linear(prev_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Initialize and train the traditional neural network\n",
    "def train_nn(model, X_train, y_train, epochs=100, learning_rate=0.01):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            acc = accuracy_score(y_train, preds.detach().numpy())\n",
    "            print(f\"Epoch {epoch}: Loss = {loss.item():.4f}, Accuracy = {acc:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        accuracy = accuracy_score(y_test, preds.numpy())\n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        cm = confusion_matrix(y_test, preds.numpy())\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "# Compare SKA with traditional neural network\n",
    "traditional_nn = TraditionalNN()\n",
    "print(\"Training Traditional Neural Network...\")\n",
    "train_nn(traditional_nn, X_train_tensor, y_train_tensor)\n",
    "evaluate_model(traditional_nn, X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Insights on SKA vs. Traditional Neural Network\n",
    "# 1. Forward Steps (K) and Convergence\n",
    "# SKA models may require more iterations (higher K) for knowledge accumulation, while traditional NNs converge via gradient-based updates.\n",
    "\n",
    "# 2. Entropy Reduction and Accuracy\n",
    "# Higher entropy reduction correlates with better classification accuracy as the model gains more discriminative knowledge.\n",
    "\n",
    "# 3. Advantages of SKA:\n",
    "# - Gradient-free learning: Avoids issues with vanishing gradients.\n",
    "# - Interpretability: Entropy and decision tracking offer better insights.\n",
    "#\n",
    "# Limitations of SKA:\n",
    "# - Computational cost: Requires multiple forward steps.\n",
    "# - Slower convergence compared to backpropagation.\n",
    "\n",
    "print(\"Comparison completed. Analyze visual outputs and performance metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
