{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Iris dataset using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform appropriate preprocessing (normalization, train/test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "30\n",
      "120\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(Xtrain))\n",
    "print(len(Xtest))\n",
    "print(len(ytrain))\n",
    "print(len(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.7, 3.8, 6.7, 2.2],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [6.1, 2.8, 4.7, 1.2]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.8, 4. , 1.2, 0.2],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [6.5, 3.2, 5.1, 2. ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest[0:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MinMaxScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = scaler.transform(Xtrain)\n",
    "Xtest = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63636364, 0.36363636, 0.61016949, 0.58333333],\n",
       "       [0.48484848, 0.40909091, 0.59322034, 0.58333333],\n",
       "       [0.51515152, 0.40909091, 0.62711864, 0.54166667],\n",
       "       [0.36363636, 0.45454545, 0.52542373, 0.5       ],\n",
       "       [0.45454545, 0.45454545, 0.54237288, 0.58333333]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42424242, 0.90909091, 0.03389831, 0.04166667],\n",
       "       [0.66666667, 0.45454545, 0.57627119, 0.54166667],\n",
       "       [0.6969697 , 0.5       , 0.62711864, 0.58333333],\n",
       "       [0.21212121, 0.68181818, 0.06779661, 0.08333333],\n",
       "       [0.63636364, 0.54545455, 0.69491525, 0.79166667]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest[0:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking the entire Xtrain for forward prop\n",
    "inputs = Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### defining the model\n",
    "class SKA_iris(nn.Module):\n",
    "    def __init__(self, input_size = 4, layer_size = [128, 64, 10, 3], K = 50):\n",
    "        super().__init__()\n",
    "        # super(SKA_iris).__init__()\n",
    "\n",
    "        #defing the input_size, layer_size, and k\n",
    "        self.input_size = input_size\n",
    "        self.layer_size = layer_size\n",
    "        self.K = K\n",
    "\n",
    "        # initilisin the weights and the bias\n",
    "        self.weights = nn.ParameterList()\n",
    "        self.bias = nn.ParameterList()\n",
    "        prev_size = input_size\n",
    "        # traverseing the number of layers and creating a randowm weights and bias matrix\n",
    "        for size in layer_size:\n",
    "            self.weights.append(nn.Parameter(torch.randn(prev_size, size) * 0.01))\n",
    "            self.bias.append(nn.Parameter(torch.randn(size)))\n",
    "            #updating the prev size to build the matrix of weights and the bias for the next layer\n",
    "            prev_size = size\n",
    "        \n",
    "        # Tracking tensors for knowledge accumulation and entropy computation\n",
    "        self.Z = [None] * len(layer_size)  # Knowledge tensors per layer\n",
    "        self.D = [None] * len(layer_size)  # Decision probability tensors\n",
    "        self.D_prev = [None] * len(layer_size)  # Previous decisions for computing shifts\n",
    "        self.delta_D = [None] * len(layer_size)  # Decision shifts per step\n",
    "        self.entropy = [None] * len(layer_size)  # Layer-wise entropy storage\n",
    "\n",
    "        # Store entropy, cosine, and output distribution history for visualization\n",
    "        self.entropy_history = [[] for _ in range(len(layer_size))]\n",
    "        self.cosine_history = [[] for _ in range(len(layer_size))]\n",
    "        self.output_history = []  # New: Store mean output distribution (3 classes) per step\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Computes SKA forward pass, storing knowledge and decisions.\"\"\"\n",
    "\n",
    "        for l in range(len(self.layer_size)):\n",
    "            # Compute knowledge tensor Z = Wx + b\n",
    "            z = torch.mm(x, self.weights[l]) + self.biases[l]\n",
    "            # Apply sigmoid activation to get decision probabilities\n",
    "            d = torch.sigmoid(z)\n",
    "            # Store values for entropy computation\n",
    "            self.Z[l] = z\n",
    "            self.D[l] = d\n",
    "            x = d  # Output becomes input for the next layer\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def calculate_entropy(self):\n",
    "        \"\"\"Computes entropy reduction and cos(theta) per layer.\"\"\"\n",
    "        total_entropy = 0\n",
    "        for l in range(len(self.layer_size)):\n",
    "            if self.Z[l] is not None and self.D_prev[l] is not None and self.D[l] is not None:\n",
    "                # Compute decision shifts\n",
    "                self.delta_D[l] = self.D[l] - self.D_prev[l]\n",
    "                # Entropy reduction using SKA formula\n",
    "                dot_product = torch.sum(self.Z[l] * self.delta_D[l])\n",
    "                layer_entropy = -1 / np.log(2) * dot_product\n",
    "                self.entropy[l] = layer_entropy.item()\n",
    "                self.entropy_history[l].append(layer_entropy.item())\n",
    "\n",
    "                # Compute cos(theta) for alignment\n",
    "                z_norm = torch.norm(self.Z[l])\n",
    "                delta_d_norm = torch.norm(self.delta_D[l])\n",
    "                if z_norm > 0 and delta_d_norm > 0:\n",
    "                    cos_theta = dot_product / (z_norm * delta_d_norm)\n",
    "                    self.cosine_history[l].append(cos_theta.item())\n",
    "                else:\n",
    "                    self.cosine_history[l].append(0.0)  # Default if norms are zero\n",
    "\n",
    "                total_entropy += layer_entropy\n",
    "        return total_entropy\n",
    "\n",
    "\n",
    "    def ska_update(self, inputs, learning_rate=0.01):\n",
    "        \"\"\"Updates weights using entropy-based learning without backpropagation.\"\"\"\n",
    "        for l in range(len(self.layer_size)):\n",
    "            if self.delta_D[l] is not None:\n",
    "                # Previous layer's output\n",
    "                prev_output = inputs.view(inputs.shape[0], -1) if l == 0 else self.D_prev[l-1]\n",
    "                # Compute sigmoid derivative: D * (1 - D)\n",
    "                d_prime = self.D[l] * (1 - self.D[l])\n",
    "                # Compute entropy gradient\n",
    "                gradient = -1 / np.log(2) * (self.Z[l] * d_prime + self.delta_D[l])\n",
    "                # Compute weight updates via outer product\n",
    "                dW = torch.matmul(prev_output.t(), gradient) / prev_output.shape[0]\n",
    "                # Update weights and biases\n",
    "                self.weights[l] = self.weights[l] - learning_rate * dW\n",
    "                self.biases[l] = self.biases[l] - learning_rate * gradient.mean(dim=0)\n",
    "\n",
    "\n",
    "    def initialize_tensors(self, batch_size):\n",
    "        \"\"\"Resets decision tensors at the start of each training iteration.\"\"\"\n",
    "        for l in range(len(self.layer_size)):\n",
    "            self.Z[l] = None         # Reset knowledge tensors\n",
    "            self.D[l] = None         # Reset current decision probabilities\n",
    "            self.D_prev[l] = None    # Reset previous decision probabilities\n",
    "            self.delta_D[l] = None   # Reset decision shifts\n",
    "            self.entropy[l] = None   # Reset entropy storage\n",
    "            self.entropy_history[l] = []  # Reset entropy history\n",
    "            self.cosine_history[l] = []   # Reset cosine history\n",
    "        self.output_history = []  # Reset output history\n",
    "\n",
    "\n",
    "    def visualize_entropy_heatmap(self, step):\n",
    "        \"\"\"Dynamically scales the heatmap range and visualizes entropy reduction.\"\"\"\n",
    "        entropy_data = np.array(self.entropy_history)\n",
    "        vmin = np.min(entropy_data)  # Dynamically set minimum entropy value\n",
    "        vmax = 0.0  # Keep 0 as the upper limit for standardization\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(entropy_data, cmap=\"Blues_r\", vmin=vmin, vmax=vmax,  \n",
    "                    xticklabels=range(1, entropy_data.shape[1] + 1),\n",
    "                    yticklabels=[f\"Layer {i+1}\" for i in range(len(self.layer_size))])\n",
    "        plt.title(f\"Layer-wise Entropy Heatmap (Step {step})\")\n",
    "        plt.xlabel(\"Step Index K\")\n",
    "        plt.ylabel(\"Network Layers\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"entropy_heatmap_step_{step}.png\")\n",
    "        plt.show(block=False)  # Non-blocking\n",
    "        plt.pause(2)  # Wait for 2 seconds\n",
    "        plt.close()  # Close automatically\n",
    "\n",
    "    def visualize_cosine_heatmap(self, step):\n",
    "        \"\"\"Visualizes cos(theta) alignment heatmap with a diverging scale.\"\"\"\n",
    "        cosine_data = np.array(self.cosine_history)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(cosine_data, cmap=\"coolwarm_r\", vmin=-1.0, vmax=1.0,  \n",
    "                    xticklabels=range(1, cosine_data.shape[1] + 1),\n",
    "                    yticklabels=[f\"Layer {i+1}\" for i in range(len(self.layer_size))])\n",
    "        plt.title(f\"Layer-wise Cos(\\u03B8) Alignment Heatmap (Step {step})\")\n",
    "        plt.xlabel(\"Step Index K\")\n",
    "        plt.ylabel(\"Network Layers\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"cosine_heatmap_step_{step}.png\")\n",
    "        plt.show(block=False)  # Non-blocking\n",
    "        plt.pause(2)  # Wait for 2 seconds\n",
    "        plt.close()  # Close automatically\n",
    "\n",
    "    def visualize_output_distribution(self):\n",
    "        \"\"\"Plots the evolution of the 10-class output distribution over K steps.\"\"\"\n",
    "        output_data = np.array(self.output_history)  # Shape: [K, 10]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(output_data)  # Plot each class as a line\n",
    "        plt.title('Output Decision Probability Evolution Across Steps (Single Pass)')\n",
    "        plt.xlabel('Step Index K')\n",
    "        plt.ylabel('Mean Sigmoid Output')\n",
    "        plt.legend([f\"Class {i}\" for i in range(10)], loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"output_distribution_single_pass.png\")\n",
    "        plt.show(block=False)  # Non-blocking\n",
    "        plt.pause(2)  # Wait for 2 seconds\n",
    "        plt.close()  # Close automatically\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Model Tranining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the adapted SKA model on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameter\n",
    "\n",
    "model = SKA_iris()\n",
    "learning_rate = 0.01\n",
    "\n",
    "# SKA training over multiple forward steps\n",
    "total_entropy = 0\n",
    "step_count = 0\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilising the tensor for first step\n",
    "model.initialize_tensors(inputs.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.63636364]],\n",
       "\n",
       "        [[0.36363636]],\n",
       "\n",
       "        [[0.61016949]],\n",
       "\n",
       "        [[0.58333333]]],\n",
       "\n",
       "\n",
       "       [[[0.48484848]],\n",
       "\n",
       "        [[0.40909091]],\n",
       "\n",
       "        [[0.59322034]],\n",
       "\n",
       "        [[0.58333333]]],\n",
       "\n",
       "\n",
       "       [[[0.51515152]],\n",
       "\n",
       "        [[0.40909091]],\n",
       "\n",
       "        [[0.62711864]],\n",
       "\n",
       "        [[0.54166667]]],\n",
       "\n",
       "\n",
       "       [[[0.36363636]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.52542373]],\n",
       "\n",
       "        [[0.5       ]]],\n",
       "\n",
       "\n",
       "       [[[0.45454545]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.54237288]],\n",
       "\n",
       "        [[0.58333333]]],\n",
       "\n",
       "\n",
       "       [[[0.12121212]],\n",
       "\n",
       "        [[0.5       ]],\n",
       "\n",
       "        [[0.10169492]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.3030303 ]],\n",
       "\n",
       "        [[0.63636364]],\n",
       "\n",
       "        [[0.11864407]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.54545455]],\n",
       "\n",
       "        [[0.40909091]],\n",
       "\n",
       "        [[0.55932203]],\n",
       "\n",
       "        [[0.5       ]]],\n",
       "\n",
       "\n",
       "       [[[0.21212121]],\n",
       "\n",
       "        [[0.81818182]],\n",
       "\n",
       "        [[0.08474576]],\n",
       "\n",
       "        [[0.08333333]]],\n",
       "\n",
       "\n",
       "       [[[0.15151515]],\n",
       "\n",
       "        [[0.22727273]],\n",
       "\n",
       "        [[0.59322034]],\n",
       "\n",
       "        [[0.66666667]]],\n",
       "\n",
       "\n",
       "       [[[0.36363636]],\n",
       "\n",
       "        [[0.40909091]],\n",
       "\n",
       "        [[0.44067797]],\n",
       "\n",
       "        [[0.5       ]]],\n",
       "\n",
       "\n",
       "       [[[0.33333333]],\n",
       "\n",
       "        [[0.68181818]],\n",
       "\n",
       "        [[0.05084746]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.21212121]],\n",
       "\n",
       "        [[0.59090909]],\n",
       "\n",
       "        [[0.11864407]],\n",
       "\n",
       "        [[0.16666667]]],\n",
       "\n",
       "\n",
       "       [[[0.51515152]],\n",
       "\n",
       "        [[0.36363636]],\n",
       "\n",
       "        [[0.62711864]],\n",
       "\n",
       "        [[0.45833333]]],\n",
       "\n",
       "\n",
       "       [[[0.63636364]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.81355932]],\n",
       "\n",
       "        [[0.875     ]]],\n",
       "\n",
       "\n",
       "       [[[0.48484848]],\n",
       "\n",
       "        [[0.09090909]],\n",
       "\n",
       "        [[0.6779661 ]],\n",
       "\n",
       "        [[0.58333333]]],\n",
       "\n",
       "\n",
       "       [[[1.        ]],\n",
       "\n",
       "        [[0.27272727]],\n",
       "\n",
       "        [[1.        ]],\n",
       "\n",
       "        [[0.91666667]]],\n",
       "\n",
       "\n",
       "       [[[0.42424242]],\n",
       "\n",
       "        [[0.27272727]],\n",
       "\n",
       "        [[0.50847458]],\n",
       "\n",
       "        [[0.45833333]]],\n",
       "\n",
       "\n",
       "       [[[0.60606061]],\n",
       "\n",
       "        [[0.54545455]],\n",
       "\n",
       "        [[0.72881356]],\n",
       "\n",
       "        [[0.91666667]]],\n",
       "\n",
       "\n",
       "       [[[0.72727273]],\n",
       "\n",
       "        [[0.54545455]],\n",
       "\n",
       "        [[0.83050847]],\n",
       "\n",
       "        [[0.91666667]]],\n",
       "\n",
       "\n",
       "       [[[0.48484848]],\n",
       "\n",
       "        [[0.31818182]],\n",
       "\n",
       "        [[0.69491525]],\n",
       "\n",
       "        [[0.625     ]]],\n",
       "\n",
       "\n",
       "       [[[0.6969697 ]],\n",
       "\n",
       "        [[0.59090909]],\n",
       "\n",
       "        [[0.79661017]],\n",
       "\n",
       "        [[1.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.6969697 ]],\n",
       "\n",
       "        [[0.59090909]],\n",
       "\n",
       "        [[0.79661017]],\n",
       "\n",
       "        [[0.83333333]]],\n",
       "\n",
       "\n",
       "       [[[0.54545455]],\n",
       "\n",
       "        [[0.63636364]],\n",
       "\n",
       "        [[0.74576271]],\n",
       "\n",
       "        [[0.91666667]]],\n",
       "\n",
       "\n",
       "       [[[0.18181818]],\n",
       "\n",
       "        [[0.59090909]],\n",
       "\n",
       "        [[0.06779661]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.03030303]],\n",
       "\n",
       "        [[0.13636364]],\n",
       "\n",
       "        [[0.05084746]],\n",
       "\n",
       "        [[0.08333333]]],\n",
       "\n",
       "\n",
       "       [[[0.06060606]],\n",
       "\n",
       "        [[0.72727273]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.72727273]],\n",
       "\n",
       "        [[0.36363636]],\n",
       "\n",
       "        [[0.6440678 ]],\n",
       "\n",
       "        [[0.54166667]]],\n",
       "\n",
       "\n",
       "       [[[0.42424242]],\n",
       "\n",
       "        [[0.31818182]],\n",
       "\n",
       "        [[0.69491525]],\n",
       "\n",
       "        [[0.75      ]]],\n",
       "\n",
       "\n",
       "       [[[0.15151515]],\n",
       "\n",
       "        [[0.72727273]],\n",
       "\n",
       "        [[0.06779661]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.09090909]],\n",
       "\n",
       "        [[0.54545455]],\n",
       "\n",
       "        [[0.10169492]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.60606061]],\n",
       "\n",
       "        [[0.40909091]],\n",
       "\n",
       "        [[0.55932203]],\n",
       "\n",
       "        [[0.5       ]]],\n",
       "\n",
       "\n",
       "       [[[0.81818182]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.83050847]],\n",
       "\n",
       "        [[0.83333333]]],\n",
       "\n",
       "\n",
       "       [[[1.        ]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.86440678]],\n",
       "\n",
       "        [[0.91666667]]],\n",
       "\n",
       "\n",
       "       [[[0.36363636]],\n",
       "\n",
       "        [[0.22727273]],\n",
       "\n",
       "        [[0.49152542]],\n",
       "\n",
       "        [[0.41666667]]],\n",
       "\n",
       "\n",
       "       [[[0.18181818]],\n",
       "\n",
       "        [[0.13636364]],\n",
       "\n",
       "        [[0.38983051]],\n",
       "\n",
       "        [[0.375     ]]],\n",
       "\n",
       "\n",
       "       [[[0.63636364]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.71186441]],\n",
       "\n",
       "        [[0.79166667]]],\n",
       "\n",
       "\n",
       "       [[[0.24242424]],\n",
       "\n",
       "        [[0.63636364]],\n",
       "\n",
       "        [[0.06779661]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.39393939]],\n",
       "\n",
       "        [[0.36363636]],\n",
       "\n",
       "        [[0.52542373]],\n",
       "\n",
       "        [[0.5       ]]],\n",
       "\n",
       "\n",
       "       [[[0.06060606]],\n",
       "\n",
       "        [[0.54545455]],\n",
       "\n",
       "        [[0.06779661]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.84848485]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.81355932]],\n",
       "\n",
       "        [[0.625     ]]],\n",
       "\n",
       "\n",
       "       [[[0.57575758]],\n",
       "\n",
       "        [[0.22727273]],\n",
       "\n",
       "        [[0.6779661 ]],\n",
       "\n",
       "        [[0.75      ]]],\n",
       "\n",
       "\n",
       "       [[[0.21212121]],\n",
       "\n",
       "        [[0.63636364]],\n",
       "\n",
       "        [[0.08474576]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.18181818]],\n",
       "\n",
       "        [[0.68181818]],\n",
       "\n",
       "        [[0.10169492]],\n",
       "\n",
       "        [[0.20833333]]],\n",
       "\n",
       "\n",
       "       [[[0.96969697]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.94915254]],\n",
       "\n",
       "        [[0.83333333]]],\n",
       "\n",
       "\n",
       "       [[[0.57575758]],\n",
       "\n",
       "        [[0.40909091]],\n",
       "\n",
       "        [[0.77966102]],\n",
       "\n",
       "        [[0.70833333]]],\n",
       "\n",
       "\n",
       "       [[[0.48484848]],\n",
       "\n",
       "        [[0.63636364]],\n",
       "\n",
       "        [[0.59322034]],\n",
       "\n",
       "        [[0.625     ]]],\n",
       "\n",
       "\n",
       "       [[[0.24242424]],\n",
       "\n",
       "        [[0.95454545]],\n",
       "\n",
       "        [[0.08474576]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.6969697 ]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.6779661 ]],\n",
       "\n",
       "        [[0.66666667]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.05084746]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.18181818]],\n",
       "\n",
       "        [[0.63636364]],\n",
       "\n",
       "        [[0.08474576]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.33333333]],\n",
       "\n",
       "        [[1.        ]],\n",
       "\n",
       "        [[0.06779661]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.21212121]],\n",
       "\n",
       "        [[0.68181818]],\n",
       "\n",
       "        [[0.06779661]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.12121212]],\n",
       "\n",
       "        [[0.63636364]],\n",
       "\n",
       "        [[0.10169492]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.6969697 ]],\n",
       "\n",
       "        [[0.5       ]],\n",
       "\n",
       "        [[0.77966102]],\n",
       "\n",
       "        [[0.95833333]]],\n",
       "\n",
       "\n",
       "       [[[0.15151515]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.06779661]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.75757576]],\n",
       "\n",
       "        [[0.54545455]],\n",
       "\n",
       "        [[0.79661017]],\n",
       "\n",
       "        [[0.91666667]]],\n",
       "\n",
       "\n",
       "       [[[0.33333333]],\n",
       "\n",
       "        [[0.27272727]],\n",
       "\n",
       "        [[0.57627119]],\n",
       "\n",
       "        [[0.45833333]]],\n",
       "\n",
       "\n",
       "       [[[0.54545455]],\n",
       "\n",
       "        [[0.36363636]],\n",
       "\n",
       "        [[0.6440678 ]],\n",
       "\n",
       "        [[0.70833333]]],\n",
       "\n",
       "\n",
       "       [[[0.18181818]],\n",
       "\n",
       "        [[0.63636364]],\n",
       "\n",
       "        [[0.10169492]],\n",
       "\n",
       "        [[0.125     ]]],\n",
       "\n",
       "\n",
       "       [[[0.51515152]],\n",
       "\n",
       "        [[0.36363636]],\n",
       "\n",
       "        [[0.50847458]],\n",
       "\n",
       "        [[0.5       ]]],\n",
       "\n",
       "\n",
       "       [[[0.15151515]],\n",
       "\n",
       "        [[0.5       ]],\n",
       "\n",
       "        [[0.08474576]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[1.        ]],\n",
       "\n",
       "        [[0.81818182]],\n",
       "\n",
       "        [[0.96610169]],\n",
       "\n",
       "        [[0.875     ]]],\n",
       "\n",
       "\n",
       "       [[[0.33333333]],\n",
       "\n",
       "        [[0.18181818]],\n",
       "\n",
       "        [[0.45762712]],\n",
       "\n",
       "        [[0.375     ]]],\n",
       "\n",
       "\n",
       "       [[[0.60606061]],\n",
       "\n",
       "        [[0.54545455]],\n",
       "\n",
       "        [[0.59322034]],\n",
       "\n",
       "        [[0.58333333]]],\n",
       "\n",
       "\n",
       "       [[[0.57575758]],\n",
       "\n",
       "        [[0.13636364]],\n",
       "\n",
       "        [[0.57627119]],\n",
       "\n",
       "        [[0.5       ]]],\n",
       "\n",
       "\n",
       "       [[[0.39393939]],\n",
       "\n",
       "        [[0.81818182]],\n",
       "\n",
       "        [[0.11864407]],\n",
       "\n",
       "        [[0.08333333]]],\n",
       "\n",
       "\n",
       "       [[[0.60606061]],\n",
       "\n",
       "        [[0.36363636]],\n",
       "\n",
       "        [[0.77966102]],\n",
       "\n",
       "        [[0.83333333]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.54545455]],\n",
       "\n",
       "        [[0.05084746]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.66666667]],\n",
       "\n",
       "        [[0.40909091]],\n",
       "\n",
       "        [[0.61016949]],\n",
       "\n",
       "        [[0.5       ]]],\n",
       "\n",
       "\n",
       "       [[[0.3030303 ]],\n",
       "\n",
       "        [[0.77272727]],\n",
       "\n",
       "        [[0.08474576]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.24242424]],\n",
       "\n",
       "        [[0.31818182]],\n",
       "\n",
       "        [[0.49152542]],\n",
       "\n",
       "        [[0.54166667]]],\n",
       "\n",
       "\n",
       "       [[[0.3030303 ]],\n",
       "\n",
       "        [[0.63636364]],\n",
       "\n",
       "        [[0.08474576]],\n",
       "\n",
       "        [[0.125     ]]],\n",
       "\n",
       "\n",
       "       [[[0.27272727]],\n",
       "\n",
       "        [[0.77272727]],\n",
       "\n",
       "        [[0.08474576]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.42424242]],\n",
       "\n",
       "        [[0.36363636]],\n",
       "\n",
       "        [[0.69491525]],\n",
       "\n",
       "        [[0.95833333]]],\n",
       "\n",
       "\n",
       "       [[[0.57575758]],\n",
       "\n",
       "        [[0.22727273]],\n",
       "\n",
       "        [[0.66101695]],\n",
       "\n",
       "        [[0.58333333]]],\n",
       "\n",
       "\n",
       "       [[[0.21212121]],\n",
       "\n",
       "        [[0.81818182]],\n",
       "\n",
       "        [[0.10169492]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.63636364]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.76271186]],\n",
       "\n",
       "        [[0.70833333]]],\n",
       "\n",
       "\n",
       "       [[[0.87878788]],\n",
       "\n",
       "        [[0.40909091]],\n",
       "\n",
       "        [[0.89830508]],\n",
       "\n",
       "        [[0.70833333]]],\n",
       "\n",
       "\n",
       "       [[[0.3030303 ]],\n",
       "\n",
       "        [[0.86363636]],\n",
       "\n",
       "        [[0.05084746]],\n",
       "\n",
       "        [[0.125     ]]],\n",
       "\n",
       "\n",
       "       [[[0.21212121]],\n",
       "\n",
       "        [[0.81818182]],\n",
       "\n",
       "        [[0.15254237]],\n",
       "\n",
       "        [[0.125     ]]],\n",
       "\n",
       "\n",
       "       [[[0.75757576]],\n",
       "\n",
       "        [[0.5       ]],\n",
       "\n",
       "        [[0.69491525]],\n",
       "\n",
       "        [[0.91666667]]],\n",
       "\n",
       "\n",
       "       [[[1.        ]],\n",
       "\n",
       "        [[0.36363636]],\n",
       "\n",
       "        [[0.96610169]],\n",
       "\n",
       "        [[0.79166667]]],\n",
       "\n",
       "\n",
       "       [[[0.54545455]],\n",
       "\n",
       "        [[0.09090909]],\n",
       "\n",
       "        [[0.59322034]],\n",
       "\n",
       "        [[0.58333333]]],\n",
       "\n",
       "\n",
       "       [[[0.36363636]],\n",
       "\n",
       "        [[0.31818182]],\n",
       "\n",
       "        [[0.54237288]],\n",
       "\n",
       "        [[0.5       ]]],\n",
       "\n",
       "\n",
       "       [[[0.33333333]],\n",
       "\n",
       "        [[0.22727273]],\n",
       "\n",
       "        [[0.50847458]],\n",
       "\n",
       "        [[0.5       ]]],\n",
       "\n",
       "\n",
       "       [[[0.18181818]],\n",
       "\n",
       "        [[0.68181818]],\n",
       "\n",
       "        [[0.05084746]],\n",
       "\n",
       "        [[0.08333333]]],\n",
       "\n",
       "\n",
       "       [[[0.6969697 ]],\n",
       "\n",
       "        [[0.22727273]],\n",
       "\n",
       "        [[0.81355932]],\n",
       "\n",
       "        [[0.70833333]]],\n",
       "\n",
       "\n",
       "       [[[0.42424242]],\n",
       "\n",
       "        [[0.31818182]],\n",
       "\n",
       "        [[0.52542373]],\n",
       "\n",
       "        [[0.375     ]]],\n",
       "\n",
       "\n",
       "       [[[0.72727273]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.76271186]],\n",
       "\n",
       "        [[0.83333333]]],\n",
       "\n",
       "\n",
       "       [[[0.18181818]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.42372881]],\n",
       "\n",
       "        [[0.375     ]]],\n",
       "\n",
       "\n",
       "       [[[0.15151515]],\n",
       "\n",
       "        [[0.18181818]],\n",
       "\n",
       "        [[0.38983051]],\n",
       "\n",
       "        [[0.375     ]]],\n",
       "\n",
       "\n",
       "       [[[0.42424242]],\n",
       "\n",
       "        [[0.31818182]],\n",
       "\n",
       "        [[0.49152542]],\n",
       "\n",
       "        [[0.45833333]]],\n",
       "\n",
       "\n",
       "       [[[0.39393939]],\n",
       "\n",
       "        [[0.36363636]],\n",
       "\n",
       "        [[0.59322034]],\n",
       "\n",
       "        [[0.5       ]]],\n",
       "\n",
       "\n",
       "       [[[0.57575758]],\n",
       "\n",
       "        [[0.31818182]],\n",
       "\n",
       "        [[0.66101695]],\n",
       "\n",
       "        [[0.70833333]]],\n",
       "\n",
       "\n",
       "       [[[0.18181818]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.10169492]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.51515152]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.61016949]],\n",
       "\n",
       "        [[0.54166667]]],\n",
       "\n",
       "\n",
       "       [[[0.12121212]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.06779661]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.48484848]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.6440678 ]],\n",
       "\n",
       "        [[0.70833333]]],\n",
       "\n",
       "\n",
       "       [[[0.39393939]],\n",
       "\n",
       "        [[0.40909091]],\n",
       "\n",
       "        [[0.54237288]],\n",
       "\n",
       "        [[0.5       ]]],\n",
       "\n",
       "\n",
       "       [[[0.84848485]],\n",
       "\n",
       "        [[0.72727273]],\n",
       "\n",
       "        [[0.86440678]],\n",
       "\n",
       "        [[1.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.42424242]],\n",
       "\n",
       "        [[0.31818182]],\n",
       "\n",
       "        [[0.69491525]],\n",
       "\n",
       "        [[0.75      ]]],\n",
       "\n",
       "\n",
       "       [[[0.06060606]],\n",
       "\n",
       "        [[0.5       ]],\n",
       "\n",
       "        [[0.08474576]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.09090909]],\n",
       "\n",
       "        [[0.54545455]],\n",
       "\n",
       "        [[0.05084746]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.48484848]],\n",
       "\n",
       "        [[0.09090909]],\n",
       "\n",
       "        [[0.50847458]],\n",
       "\n",
       "        [[0.375     ]]],\n",
       "\n",
       "\n",
       "       [[[0.57575758]],\n",
       "\n",
       "        [[0.59090909]],\n",
       "\n",
       "        [[0.62711864]],\n",
       "\n",
       "        [[0.625     ]]],\n",
       "\n",
       "\n",
       "       [[[0.39393939]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.54237288]],\n",
       "\n",
       "        [[0.45833333]]],\n",
       "\n",
       "\n",
       "       [[[0.36363636]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.59322034]],\n",
       "\n",
       "        [[0.58333333]]],\n",
       "\n",
       "\n",
       "       [[[0.90909091]],\n",
       "\n",
       "        [[0.36363636]],\n",
       "\n",
       "        [[0.86440678]],\n",
       "\n",
       "        [[0.75      ]]],\n",
       "\n",
       "\n",
       "       [[[0.33333333]],\n",
       "\n",
       "        [[0.13636364]],\n",
       "\n",
       "        [[0.50847458]],\n",
       "\n",
       "        [[0.5       ]]],\n",
       "\n",
       "\n",
       "       [[[0.6969697 ]],\n",
       "\n",
       "        [[0.45454545]],\n",
       "\n",
       "        [[0.71186441]],\n",
       "\n",
       "        [[0.91666667]]],\n",
       "\n",
       "\n",
       "       [[[0.75757576]],\n",
       "\n",
       "        [[0.5       ]],\n",
       "\n",
       "        [[0.74576271]],\n",
       "\n",
       "        [[0.83333333]]],\n",
       "\n",
       "\n",
       "       [[[0.45454545]],\n",
       "\n",
       "        [[0.54545455]],\n",
       "\n",
       "        [[0.6440678 ]],\n",
       "\n",
       "        [[0.70833333]]],\n",
       "\n",
       "\n",
       "       [[[0.21212121]],\n",
       "\n",
       "        [[0.77272727]],\n",
       "\n",
       "        [[0.08474576]],\n",
       "\n",
       "        [[0.125     ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.40909091]],\n",
       "\n",
       "        [[0.06779661]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.78787879]],\n",
       "\n",
       "        [[0.54545455]],\n",
       "\n",
       "        [[0.62711864]],\n",
       "\n",
       "        [[0.54166667]]],\n",
       "\n",
       "\n",
       "       [[[0.18181818]],\n",
       "\n",
       "        [[0.54545455]],\n",
       "\n",
       "        [[0.03389831]],\n",
       "\n",
       "        [[0.04166667]]],\n",
       "\n",
       "\n",
       "       [[[0.84848485]],\n",
       "\n",
       "        [[0.54545455]],\n",
       "\n",
       "        [[0.84745763]],\n",
       "\n",
       "        [[0.70833333]]],\n",
       "\n",
       "\n",
       "       [[[0.57575758]],\n",
       "\n",
       "        [[0.36363636]],\n",
       "\n",
       "        [[0.69491525]],\n",
       "\n",
       "        [[0.58333333]]],\n",
       "\n",
       "\n",
       "       [[[0.57575758]],\n",
       "\n",
       "        [[0.59090909]],\n",
       "\n",
       "        [[0.84745763]],\n",
       "\n",
       "        [[1.        ]]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4, 1, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.expand_dims(inputs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mm(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Process K forward steps (without backpropagation)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(model\u001b[38;5;241m.\u001b[39mK):\n\u001b[0;32m----> 3\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Store mean output distribution for the final layer\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39moutput_history\u001b[38;5;241m.\u001b[39mappend(outputs\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# [10] vector\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[70], line 40\u001b[0m, in \u001b[0;36mSKA_iris.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Computes SKA forward pass, storing knowledge and decisions.\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_size)):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Compute knowledge tensor Z = Wx + b\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases[l]\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Apply sigmoid activation to get decision probabilities\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(z)\n",
      "\u001b[0;31mTypeError\u001b[0m: mm(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# Process K forward steps (without backpropagation)\n",
    "for k in range(model.K):\n",
    "    outputs = model.forward(inputs)\n",
    "    # Store mean output distribution for the final layer\n",
    "    model.output_history.append(outputs.mean(dim=0).detach().cpu().numpy())  # [10] vector\n",
    "    if k > 0:  # Compute entropy after first step\n",
    "        batch_entropy = model.calculate_entropy()\n",
    "        model.ska_update(inputs, learning_rate)\n",
    "        total_entropy += batch_entropy\n",
    "        step_count += 1\n",
    "        print(f'Step: {k}, Total Steps: {step_count}, Entropy: {batch_entropy:.4f}')\n",
    "        model.visualize_entropy_heatmap(step_count)\n",
    "        model.visualize_cosine_heatmap(step_count)  # Add cosine heatmap\n",
    "    # Update previous decision tensors\n",
    "    model.D_prev = [d.clone().detach() if d is not None else None for d in model.D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
